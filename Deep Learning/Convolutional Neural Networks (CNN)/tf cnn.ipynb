{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ec6a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow.python.framework.ops as ops\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cebe055",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "933f7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholder(n_H0,n_W0,n_C0,n_y):\n",
    "    X = tf1.placeholder(shape = [None, n_H0,n_W0,n_C0],dtype= tf.float32, name='X')\n",
    "    y = tf1.placeholder(shape = [None, n_y], dtype= tf.int8, name='y')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7e46625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    tf1.set_random_seed(1)\n",
    "    W1 = tf1.get_variable(\"W1\",[4,4,3,8],initializer= tf.initializers.glorot_uniform(seed= 0))\n",
    "    W2 = tf1.get_variable(\"W2\",[2,2,8,16],initializer= tf.initializers.glorot_uniform(seed= 0))\n",
    "    params = {\"W1\":W1,\"W2\":W2}\n",
    "    return params\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a51c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,params):\n",
    "    \n",
    "    w1 = params.get(\"W1\")\n",
    "    w2 = params.get(\"w2\")\n",
    "    s=1\n",
    "    Z1 = tf.nn.conv2d(X , w1, strides=[1,s,s,1],padding= 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    s= 8\n",
    "    f= 8\n",
    "    P1 = tf.nn.max_pool(A1, ksize= [1,f,f,1], strides=[1,s,s,1], padding='SAME')\n",
    "    \n",
    "    s=1\n",
    "    Z2 = tf.nn.conv2d(P1 , w2, strides=[1,s,s,1],padding= 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    s= 4\n",
    "    f= 4\n",
    "    P2 = tf.nn.max_pool(A2, ksize= [1,f,f,1], strides=[1,s,s,1], padding='SAME')\n",
    "    \n",
    "    F = tf1.layers.flatten(P2)\n",
    "    num_outputs = 6 \n",
    "    Z3 = tf1.layers.dense(F,num_outputs= num_outputs)\n",
    "    \n",
    "    return Z3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc2fbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= Z3, labels= y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6f635e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_bathces(x, y, batch_size,seed):\n",
    "    m = x.shape[0]\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_x = x[permutation,:]\n",
    "    shuffled_y = y[permutation,:].reshape((m,y.shape[1]))\n",
    "    num_complete_minibatches = math.floor(m/batch_size)\n",
    "    for k in range(0,num_complete_minibatches):\n",
    "        batch_x = shuffled_x[ k*batch_size:k*batch_size+batch_size,:]\n",
    "        batch_y = shuffled_y[ k*batch_size:k*batch_size+batch_size,:]\n",
    "        mini_batches.append((batch_x,batch_y))\n",
    "    if m % batch_size != 0 :\n",
    "        batch_x = shuffled_x[ num_complete_minibatches*batch_size:m,:]\n",
    "        batch_y = shuffled_y[ num_complete_minibatches*batch_size:m,:]\n",
    "        mini_batches.append((batch_x,batch_y))\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "516a329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y, x_test, y_test, lr= 0.009, epochs= 100, batch_size= 64, print_cost= True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    tf1.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (m, n_H0, n_W0, n_C0) = x.shape\n",
    "    n_y = y.shape[1]\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    X , Y = create_placeholder(n_H0, n_W0, n_C0, n_y)\n",
    "    params = init_params()\n",
    "    \n",
    "    Z3 = forward_propagation(X, params)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf1.train.AdamOptimizer(learning_rate=lr).minimize(loss= cost)\n",
    "    \n",
    "    init = tf1.global_variables_initializer()\n",
    "    \n",
    "    with tf1.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(epochs):\n",
    "            batch_cost = 0 \n",
    "            num_batches = int(m/batch_size)\n",
    "            seed +=1\n",
    "            batches = random_mini_bathces(x, y, batch_size, seed)\n",
    "            for batch in batches:\n",
    "                (batch_x,bathc_y) = batch\n",
    "                \n",
    "                _,temp_cost = sess.run([optimizer, cost], fedd_dict= {X:batch_x, Y:batch_y})\n",
    "                batch_cost += temp_cost / num_batches\n",
    "            \n",
    "            if print_cost and epoch % 5 == 0:\n",
    "                print(f\"cost after epoch {epoch} : {batch_cost}\")\n",
    "            if print_cost  and epoch % 1 == 0:\n",
    "                costs.append(batch_cost)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlable('iters (per ten) ')\n",
    "        plt.title(\"learning rate = \"+ str(lr))\n",
    "        \n",
    "        predict_op = tf.argmax(Z3,1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,'float'))\n",
    "        print(accuracy)\n",
    "        train_acc = accuracy.eval({X:x,Y:y})\n",
    "        test_acc = accuracy.eval({X:x_test, Y:y_test})\n",
    "        \n",
    "        print(f'train accuracy {train_acc}')\n",
    "        print(f'test accuracy {test_acc}')\n",
    "        \n",
    "        return train_acc, test_acc, params\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3ab12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import  mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b382548",
   "metadata": {},
   "outputs": [],
   "source": [
    " (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24dc4933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train= x_train.reshape((x_train.shape[0],x_train.shape[1],x_train.shape[2],1))\n",
    "x_test= x_test.reshape((x_test.shape[0],x_test.shape[1],x_test.shape[2],1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e09353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "187994ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train.reshape((y_train.shape[0],1))\n",
    "y_test= y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4af75dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e997247",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Depth of input (1) is not a multiple of input depth of filter (3) for '{{node Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](X, Conv2D/ReadVariableOp)' with input shapes: [?,28,28,1], [4,4,3,8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (_,_,params) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(x, y, x_test, y_test, lr, epochs, batch_size, print_cost)\u001b[0m\n\u001b[1;32m     11\u001b[0m X , Y \u001b[38;5;241m=\u001b[39m create_placeholder(n_H0, n_W0, n_C0, n_y)\n\u001b[1;32m     12\u001b[0m params \u001b[38;5;241m=\u001b[39m init_params()\n\u001b[0;32m---> 14\u001b[0m Z3 \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m cost \u001b[38;5;241m=\u001b[39m compute_cost(Z3, Y)\n\u001b[1;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate\u001b[38;5;241m=\u001b[39mlr)\u001b[38;5;241m.\u001b[39mminimize(loss\u001b[38;5;241m=\u001b[39m cost)\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(X, params)\u001b[0m\n\u001b[1;32m      4\u001b[0m w2 \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m Z1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m A1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(Z1)\n\u001b[1;32m      8\u001b[0m s\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1969\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1966\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1968\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[0;31mValueError\u001b[0m: Depth of input (1) is not a multiple of input depth of filter (3) for '{{node Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](X, Conv2D/ReadVariableOp)' with input shapes: [?,28,28,1], [4,4,3,8]."
     ]
    }
   ],
   "source": [
    "(_,_,params) = model(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eda9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7a57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddab88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
